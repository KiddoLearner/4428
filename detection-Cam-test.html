<!doctype html>
<html lang="en">
  <head>
    <style>
    .videoView, .classifyOnClick {
    position: relative;
    float: left;
    width: 48%;
    margin: 2% 1%;
    cursor: pointer;
    }
    /*ObjectPredection*/ 
    
    .highlighter {
      background: rgba(0, 255, 0, 0.25);
      border: 1px dashed #fff;
      z-index: 998;
      position: absolute;
    }

    #pObject{
        position: absolute;
        z-index: 998;
    }
    
    video {
        clear: both;
        display: block;
    }

    section {
        opacity: 1;
        transition: opacity 500ms ease-in-out;
    }

    .removed {
    display: none;
    }

    .invisible {
    opacity: 0.2;
    }

    .videoView p, .classifyOnClick p {
    position: absolute;
    padding: 5px;
    background-color: rgba(255, 111, 0, 0.85);
    color: #FFF;
    border: 1px dashed rgba(255, 255, 255, 0.7);
    z-index: 10;
    font-size: 12px;
    margin: 0;
    }

    #time-date{
        position: absolute;
      top: 0px;
      left: 0px;
      font: 0px Arial;
      color: white;
      z-index: -1;
    }

    #liveView{
        position: relative;
    }
    #faceRecog{
        position:absolute; top:0px; left:0px;
        z-index: -1;
    }

    </style>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>EIE4428 MiniProject Remote</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
  </head>
  
  <body>
 <nav class="navbar navbar-expand-lg bg-light">
  <div class="container-fluid">
    <a class="navbar-brand" href="#">EIE4428 Mini-Project</a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
    </button>
    <div class="collapse navbar-collapse" id="navbarNavDropdown">
      <ul class="navbar-nav">
        <li class="nav-item">
          <span class="nav-link">Mak Cheuk Ming</span>
        </li>
        <li class="nav-item">
            <span class="nav-link">Tam Siu Kin</span>
        </li>
      </ul>
    </div>
  </div>
</nav>

    
    <div class="container">
        <h1>Are you ready to connect to the host?</h1> 
    <div class="row-g-5">
        <div class="col mod-6">
            <!--<section class="make-center invisible" id="demos">
                <p style="margin: 0; padding: 0; padding-bottom: 20px;">
                    <span>Supported Codec in your device:</span>
                    <select id="codecPreferences" class="form-select" disabled>
                        <option selected value="">Codec Lists</option>
                    </p> </select> -->
                <input type="text" id="broadcast-id" value="EIE4428-Project" autocorrect=off autocapitalize=off size=20 disabled>
                <button id="open-or-join">Join Broadcast</button>

                <div class="make-center" id="broadcast-viewers-counter"></div>
                <div id="liveView" class="videoView" style="display: inline-block;">
                <video  id="video-view" controls loop width="100%" height="100%" ></video>
                <canvas id="audioWave" hidden></canvas>
                <video id="video-recorded" width="100%" height="100%" controls hidden></video>
                <canvas id="capture" hidden></canvas>
               
                <video  id="video-preview" controls loop width="100%" height="100%" style = "margin-left:-999px" ></video>
               
                <canvas id="time-date"></canvas>
                <canvas id="faceRecog"></canvas>
                </div>
        </div>
        <div class="col-mod-6"> 
            <br>
            <div class="col-mod-6">
                <button id="AudioWaveOn" type="button" class="btn btn-primary" disabled>&nbsp;&nbsp;&nbsp;AudioWaveOn&nbsp;&nbsp;&nbsp;</button>
                <button id="AudioWaveOff" type="button" class="btn btn-primary" disabled>&nbsp;&nbsp;AudioWaveOff&nbsp;&nbsp;</button>
            </div><br>
            <div class="col-mod-6">
                <button id="startRecord" type="button" class="btn btn-primary" disabled>&nbsp;&nbsp;Start Recording&nbsp;&nbsp;&nbsp;</button>
                <button id="stopRecord" type="button" class="btn btn-primary" disabled>&nbsp;Stop Recording&nbsp;</button>
            </div><br>
            <div class="col-mod-6">
                <button id="objectDetectOn" type="button" class="btn btn-primary" disabled>&nbsp;ObjectDetectOn &nbsp;</button>
                <button id="objectDetectOff" type="button" class="btn btn-primary" disabled>&nbsp;ObjectDetectOff&nbsp;</button>
            </div><br>
            <div class="col-mod-6">
                <button id="displayRecord" type="button" class="btn btn-primary" disabled>Display Recording</button>
                <button id="Screenshot" type="button" class="btn btn-primary" disabled>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Screenshot&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</button>
            </div><br>
        </div>                 
    </div>
    </div>
    <div class="container-fluid">
    <div class="row-g-5">
        <div class="col mod-6" class="make-center">
            
            
        </div>
    </div>
    </div>

  <script src="https://muazkhan.com:9001/dist/RTCMultiConnection.min.js"></script>
  <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
<script src="https://muazkhan.com:9001/socket.io/socket.io.js"></script>
  <script src="https://www.webrtc-experiment.com/RecordRTC.js"></script>
  

<!-- TensorFlow.js library -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js" type="text/javascript"></script>
<!--TensorFlow - Face Recognize-->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<!-- coco-ssd model -> recognize things in images -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>


<!-- CodecsHandler -->
<script src="CodecsHandler.js"></script>
  <script>
// recording is disabled because it is resulting for browser-crash
// if you enable below line, please also uncomment above "RecordRTC.js"
//document.getElementById("video-recorded").style.display="none";
document.getElementById("broadcast-id").disabled=true;

var enableRecordings = true;

var connection = new RTCMultiConnection();
connection.codecs.video  = 'VP9';
connection.preferVP9 = true;

// https://www.rtcmulticonnection.org/docs/iceServers/
// use your own TURN-server here!
// first step, ignore default STUN+TURN servers
connection.iceServers = [];

// last step, set TURN url (recommended)
connection.iceServers.push({
    urls: 'turn:global.turn.twilio.com:3478?transport=udp',
    credential: '66CnZY4v08wSWY8tPt+1MU7Zi87/HW2hPS+1XKm6P88=',
    username: '559f681a8ce613edfd717ae9f12de947161618c35729d72301d772909a3210fa'
});   
  
// https://www.rtcmulticonnection.org/docs/iceServers/
connection.iceServers.push({
    'urls': [
     
        'stun:stun.l.google.com:19302',  
        'stun:stun1.l.google.com:19302',
        'stun:stun2.l.google.com:19302'
    ]
}); 
/*connection.iceServers = [{
    'urls': [
        'stun:stun.l.google.com:19302',
        'stun:stun1.l.google.com:19302',
        'stun:stun2.l.google.com:19302',
    ]
}];*/

// enable only relay ip-addresses
  connection.candidates = {
    turn: true,
    stun: true,
    host: false
};
console.log("checker");
console.log(connection.isInitiator);

// its mandatory in v3
connection.enableScalableBroadcast = true;

// each relaying-user should serve only 6 users
connection.maxRelayLimitPerUser = 6;

// we don't need to keep room-opened
// scalable-broadcast.js will handle stuff itself.
connection.autoCloseEntireSession = true;

// by default, socket.io server is assumed to be deployed on your own URL
connection.socketURL = '/';

// comment-out below line if you do not have your own socket.io server
 connection.socketURL = 'https://muazkhan.com:9001/';

connection.socketMessageEvent = 'scalable-media-broadcast-demo';

// document.getElementById('broadcast-id').value = connection.userid;

// user need to connect server, so that others can reach him.
connection.connectSocket(function(socket) {
    socket.on('logs', function(log) {
        document.querySelector('h1').innerHTML = "You are connecting to host EIE4428-Project";
        //document.querySelector('h1').innerHTML = log.replace(/</g, '----').replace(/>/g, '___').replace(/----/g, '(<span style="color:red;">').replace(/___/g, '</span>)');
    });

    // this event is emitted when a broadcast is already created.
    socket.on('join-broadcaster', function(hintsToJoinBroadcast) {
        console.log('join-broadcaster', hintsToJoinBroadcast);

        connection.session = hintsToJoinBroadcast.typeOfStreams;
        connection.sdpConstraints.mandatory = {
            OfferToReceiveVideo: !!connection.session.video,
            OfferToReceiveAudio: !!connection.session.audio
        };
        connection.broadcastId = hintsToJoinBroadcast.broadcastId;
        connection.join(hintsToJoinBroadcast.userid);
    });

    socket.on('rejoin-broadcast', function(broadcastId) {
        console.log('rejoin-broadcast', broadcastId);

        connection.attachStreams = [];
        socket.emit('check-broadcast-presence', broadcastId, function(isBroadcastExists) {
            if (!isBroadcastExists) {
                // the first person (i.e. real-broadcaster) MUST set his user-id
                connection.userid = broadcastId;
            }

            socket.emit('join-broadcast', {
                broadcastId: broadcastId,
                userid: connection.userid,
                typeOfStreams: connection.session
            });
        });
    });

    socket.on('broadcast-stopped', function(broadcastId) {
        // alert('Broadcast has been stopped.');
        // location.reload();
        console.error('broadcast-stopped', broadcastId);
        alert('This broadcast has been stopped.');
    });

    // this event is emitted when a broadcast is absent.
    socket.on('start-broadcasting', function(typeOfStreams) {
        console.log('start-broadcasting', typeOfStreams);

        // host i.e. sender should always use this!
        connection.sdpConstraints.mandatory = {
            OfferToReceiveVideo: false,
            OfferToReceiveAudio: false
        };
        connection.session = typeOfStreams;

        // "open" method here will capture media-stream
        // we can skip this function always; it is totally optional here.
        // we can use "connection.getUserMediaHandler" instead
        connection.open(connection.userid);
    });
});

window.onbeforeunload = function() {
    // Firefox is ugly.
    document.getElementById('open-or-join').disabled = false;
};

var videoPreview = document.getElementById('video-preview');
var videoView = document.getElementById("video-view");
videoPreview.addEventListener('loadeddata', predictWebcam);

connection.onstream = function(event) {
    if (connection.isInitiator && event.type !== 'local') {
        return;
    }
    connection.isUpperUserLeft = false;
    videoPreview.srcObject = event.stream;
    videoPreview.play();

    videoPreview.userid = event.userid;

    if (event.type === 'local') {
        videoPreview.muted = true;
    }
//if have audio, can use audio wave
    if(event.stream.getAudioTracks().length>=1){
        document.getElementById('AudioWaveOn').disabled=false;
    }

    //Time&Date on Video
    function displaytimedate(){
                    canvas.width = videoPreview.offsetWidth;
                    canvas.height = videoPreview.offsetHeight;

                    var date = new Date().toLocaleString();
                    var displaydate = date.replace(", ", " - ");
                    const ctx = canvas.getContext("2d");
                    ctx.font = "12px Arial";
                    ctx.clearRect(0, 0, canvas.width, canvas.height)
                    ctx.drawImage(canvas_face, 0, 0, canvas.width, canvas.height);
                    ctx.fillText(displaydate,10,20);
                }
                

                //var displayDate = date.getMonth() + 1 + "/" + date.getDate() + "/" + date.getYear();
                //displayDate = displayDate + ":" + date.getHours() + date.getMinutes() + ":" + date.getSeconds();
                //document.getElementById("time-date").innerHTML=displaydate;
                
                
                setInterval(displaytimedate, 30);
                

    if (connection.isInitiator == false && event.type === 'remote') {

        // he is merely relaying the media
        connection.dontCaptureUserMedia = true;
        connection.attachStreams = [event.stream];
        connection.sdpConstraints.mandatory = {
            OfferToReceiveAudio: false,
            OfferToReceiveVideo: false
        };

        connection.getSocket(function(socket) {
            socket.emit('can-relay-broadcast');

            if (connection.DetectRTC.browser.name === 'Chrome' || connection.DetectRTC.browser.name === 'Edge') {
                connection.getAllParticipants().forEach(function(p) {
                    if (p + '' != event.userid + '') {
                        var peer = connection.peers[p].peer;
                        peer.getLocalStreams().forEach(function(localStream) {
                            peer.removeStream(localStream);
                        });
                        event.stream.getTracks().forEach(function(track) {
                            peer.addTrack(track, event.stream);
                        });
                        connection.dontAttachStream = true;
                        connection.renegotiate(p);
                        connection.dontAttachStream = false;
                    }
                });
            }

            if (connection.DetectRTC.browser.name === 'Firefox') {
                // Firefox is NOT supporting removeStream method
                // that's why using alternative hack.
                // NOTE: Firefox seems unable to replace-tracks of the remote-media-stream
                // need to ask all deeper nodes to rejoin
                connection.getAllParticipants().forEach(function(p) {
                    if (p + '' != event.userid + '') {
                        connection.replaceTrack(event.stream, p);
                    }
                });
            }

               


            // Firefox seems UN_ABLE to record remote MediaStream
            // WebAudio solution merely records audio
            // so recording is skipped for Firefox.
            //  if (connection.DetectRTC.browser.name === 'Chrome') {
            //      repeatedlyRecordStream(event.stream);
            //  }
        });
    }

    // to keep room-id in cache
    localStorage.setItem(connection.socketMessageEvent, connection.sessionid);
    document.getElementById("startRecord").disabled = false;
    document.getElementById("Screenshot").disabled = false;
    document.getElementById('objectDetectOn').disabled = false;
	console.log("checker2");
    console.log(connection.codecs.video);
	console.log(event.stream.getTracks().getSettings());
};



// ask node.js server to look for a broadcast
// if broadcast is available, simply join it. i.e. "join-broadcaster" event should be emitted.
// if broadcast is absent, simply create it. i.e. "start-broadcasting" event should be fired.
document.getElementById('open-or-join').onclick = function() {
    var broadcastId = document.getElementById('broadcast-id').value;
    if (broadcastId.replace(/^\s+|\s+$/g, '').length <= 0) {
        alert('Please enter broadcast-id');
        document.getElementById('broadcast-id').focus();
        return;
    }

    document.getElementById('open-or-join').disabled = true;

    connection.extra.broadcastId = broadcastId;

    connection.session = {
        audio: true,
        video: true,
        oneway: true,
        data: true
    };
	
 



    connection.getSocket(function(socket) {
        socket.emit('check-broadcast-presence', broadcastId, function(isBroadcastExists) {
            if (!isBroadcastExists) {
                // the first person (i.e. real-broadcaster) MUST set his user-id
                connection.userid = broadcastId;
            }

            console.log('check-broadcast-presence', broadcastId, isBroadcastExists);

            socket.emit('join-broadcast', {
                broadcastId: broadcastId,
                userid: connection.userid,
                typeOfStreams: connection.session
            });
        });
    });
};







// <!-- document.getElementById('startRecord').onclick = function(){ -->

// <!-- var broadcastId = document.getElementById('broadcast-id').value; -->
// <!-- // e.type == 'remote' || 'local'  -->
//     <!-- connection.streams[broadcastId].startRecording({  -->
//         <!-- video: true  -->
//     <!-- });  -->

//     <!-- // record 10 sec audio/video  -->
//     <!-- var recordingInterval = 10 * 10000;  -->

//     <!-- setTimeout(function () {  -->
//         <!-- connection.streams[broadcastId].stopRecording(function (blob) {  -->
//             <!-- var mediaElement = document.createElement('video');  -->
//             <!-- mediaElement.src = URL.createObjectURL(blob.video);  -->
//             <!-- document.documentElement.appendChild(h2);  -->
//         <!-- });  -->
//     <!-- }, recordingInterval)  -->

// <!-- }; -->

document.getElementById('startRecord').onclick = function(){
   // console.log("test");
   document.getElementById('stopRecord').disabled = false;
   document.getElementById('startRecord').disabled = true;
    repeatedlyRecordStream(videoView.srcObject);
    
}

document.getElementById("stopRecord").addEventListener('click', stoprecord);

function stoprecord(){
   // console.log("test");
   connection.currentRecorder.stopRecording();
   document.getElementById('stopRecord').disabled = true;
   document.getElementById('startRecord').disabled = false; 
   document.getElementById('displayRecord').disabled = false;    
   console.log("recorder" + connection.currentRecorder);
  // console.log("get blob " + connection.currentRecorder.getBlob());

}

document.getElementById('displayRecord').onclick = function(){
   // var mediaElement = document.createElement('video'); 
   var mediaElement = document.getElementById("video-recorded");
    mediaElement.src = URL.createObjectURL(connection.currentRecorder.getBlob());   
     document.getElementById('video-recorded').hidden = false; 
   //var mediaElement = document.getElementById("video-recorded");
	mediaElement.play();
	console.log(connection.currentRecorder.blob);
    console.log( URL.createObjectURL(connection.currentRecorder.getBlob()));
}

document.getElementById('Screenshot').onclick = function(){
    var canvasCap = document.getElementById("capture");
    canvasCap.width = videoPreview.videoWidth;
    canvasCap.height = videoPreview.videoHeight;
    canvasCap.getContext("2d").drawImage(videoView,0,0,canvasCap.width,canvasCap.height);
    canvasCap.hidden = false;
}

connection.onstreamended = function() {};

connection.onleave = function(event) {
    if (event.userid !== videoPreview.userid) return;

    connection.getSocket(function(socket) {
        socket.emit('can-not-relay-broadcast');

        connection.isUpperUserLeft = true;

        if (allRecordedBlobs.length) {
            // playing lats recorded blob
            var lastBlob = allRecordedBlobs[allRecordedBlobs.length - 1];
            //videoPreview.src = URL.createObjectURL(lastBlob);
            videoPreview.src = URL.createObjectURL(lastBlob);
            //videoPreview.play();
            videoPreview.play();
            allRecordedBlobs = [];
        } else if (connection.currentRecorder) {
            var recorder = connection.currentRecorder;
            connection.currentRecorder = null;
            recorder.stopRecording(function() {
                if (!connection.isUpperUserLeft) return;

                videoPreview.src = URL.createObjectURL(recorder.getBlob());
                videoPreview.play();
                // videoPreview.src = URL.createObjectURL(recorder.getBlob());
                // videoView.play();
            });
        }

        if (connection.currentRecorder) {
            connection.currentRecorder.stopRecording();
            connection.currentRecorder = null;
        }
    });
};

var allRecordedBlobs = [];

function repeatedlyRecordStream(stream) {
    if (!enableRecordings) {
        return;
    }

    
    connection.currentRecorder = RecordRTC(stream, {
        type: 'video',
        mimeType: 'video/mp4'
    });

    connection.currentRecorder.startRecording();

    setTimeout(function() {
        if (connection.isUpperUserLeft || !connection.currentRecorder) {
            return;
        }

        connection.currentRecorder.stopRecording(function() {
            allRecordedBlobs.push(connection.currentRecorder.getBlob());

            if (connection.isUpperUserLeft) {
                return;
            }

            connection.currentRecorder = null;
            repeatedlyRecordStream(stream);
        });
    }, 30 * 1000); // 30-seconds
};


function disableInputButtons() {
    document.getElementById('open-or-join').disabled = true;
    document.getElementById('broadcast-id').disabled = true;
}

// // ......................................................
// // ......................Handling broadcast-id................
// // ......................................................

// var broadcastId = '';
// if (localStorage.getItem(connection.socketMessageEvent)) {
//     broadcastId = localStorage.getItem(connection.socketMessageEvent);
// } else {
//     broadcastId = connection.token();
// }
// var txtBroadcastId = document.getElementById('broadcast-id');
// txtBroadcastId.value = broadcastId;
// txtBroadcastId.onkeyup = txtBroadcastId.oninput = txtBroadcastId.onpaste = function() {
//     localStorage.setItem(connection.socketMessageEvent, this.value);
// };

// // below section detects how many users are viewing your broadcast

// connection.onNumberOfBroadcastViewersUpdated = function(event) {
//     if (!connection.isInitiator) return;

//     document.getElementById('broadcast-viewers-counter').innerHTML = 'Number of broadcast viewers: <b>' + event.numberOfBroadcastViewers + '</b>';
// };

/*const codecPreferences = document.getElementById('codecPreferences');
const supportsSetCodecPreferences = window.RTCRtpTransceiver &&
  'setCodecPreferences' in window.RTCRtpTransceiver.prototype;

  if (supportsSetCodecPreferences) {
    const {codecs} = RTCRtpSender.getCapabilities('video');
    codecs.forEach(codec => {
      if (['video/red', 'video/ulpfec', 'video/rtx'].includes(codec.mimeType)) {
        return;
      }
      const option = document.createElement('option');
      option.disabled = true;
      option.value = (codec.mimeType + ' ' + (codec.sdpFmtpLine || '')).trim();
      option.innerText = option.value;
      codecPreferences.appendChild(option);
    });
    codecPreferences.disabled = false;
  }*/


  const canvas = document.getElementById("time-date");
  const canvasview = canvas.captureStream();
  
videoView.srcObject = canvasview;
//videoView.play();
//videoPreview.style.visibility = "hidden";

// ----------------------------------------------------------
// ----------------- Face Recognition -----------------------
// ----------------------------------------------------------
var model_face = undefined;
var canvas_face = document.getElementById("faceRecog");
var ctxFace = canvas_face.getContext("2d");
// Before we can use COCO-SSD class we must wait for it to finish
// loading. Machine Learning models can be large and take a moment to
// get everything needed to run.
cocoSsd.load().then(function (loadedModel) {
  model = loadedModel;
  // Show demo section now model is ready to use.
  //demosSection.classList.remove('invisible');
});

// ----------------------------------------------------------
// ----------------- Object Detection -----------------------
// ----------------------------------------------------------
const demosSection = document.getElementById('demos');
var model = undefined;
const liveView = document.getElementById('liveView');
// Keep a reference of all the child elements we create
// so we can remove them easilly on each render.
var children = [];
// Prediction loop!
var objectRecognizeBool = false;
document.getElementById('objectDetectOn').onclick = function() {

    objectRecognizeBool = true;
    document.getElementById('objectDetectOn').disabled = true;
    document.getElementById('objectDetectOff').disabled = false;
    setTimeout(function() {
        predictWebcam();
       }, 1200)
};

document.getElementById('objectDetectOff').onclick = function() {
    document.getElementById('objectDetectOn').disabled = false;
    document.getElementById('objectDetectOff').disabled = true;

    objectRecognizeBool = false;
    for (let i = 0; i < children.length; i++) {
      liveView.removeChild(children[i]);
    }
    children.splice(0);
    clearTimeout(predictWebcam);
};

function predictWebcam() {
  // Now let's start classifying the stream.
  model.detect(videoPreview).then(function (predictions) {
    // Remove any highlighting we did previous frame.

    if(objectRecognizeBool == true){

    
    for (let i = 0; i < children.length; i++) {
      liveView.removeChild(children[i]);
    }
    children.splice(0);
    // Now lets loop through predictions and draw them to the live view if
    // they have a high confidence score.
    for (let n = 0; n < predictions.length; n++) {
      // If we are over 66% sure we are sure we classified it right, draw it!
      if (predictions[n].score > 0.66) {
        const p = document.createElement('p');
        p.setAttribute("id", "pObject");
        p.innerText = predictions[n].class  + ' - with ' 
            + Math.round(parseFloat(predictions[n].score) * 100) 
            + '% confidence.';
        // Draw in top left of bounding box outline.
        p.style = 'left: ' + predictions[n].bbox[0] + 'px;' +
            'top: ' + predictions[n].bbox[1] + 'px;' + 
            'width: ' + (predictions[n].bbox[2] - 10) + 'px;';

        // Draw the actual bounding box.
        const highlighter = document.createElement('div');
        highlighter.setAttribute('class', 'highlighter');
        highlighter.style = 'left: ' + predictions[n].bbox[0] + 'px; top: '
            + predictions[n].bbox[1] + 'px; width: ' 
            + predictions[n].bbox[2] + 'px; height: '
            + predictions[n].bbox[3] + 'px;';

        liveView.appendChild(highlighter);
        liveView.appendChild(p);
        
        // Store drawn objects in memory so we can delete them next time around.
        children.push(highlighter);
        children.push(p);
      }
    }
    
    // Call this function again to keep predicting when the browser is ready.
    window.requestAnimationFrame(predictWebcam);
}
  });
}


 //================================================================================
async function faceRecognizition(){
    const prediction = await model_face.estimateFaces(videoView, false);
    canvas_face.width = videoPreview.offsetWidth;
    canvas_face.height = videoPreview.offsetHeight;
    ctxFace.clearRect(0,0,canvas_face.width,canvas_face.height);

    console.log(prediction);
    ctxFace.drawImage(videoPreview, 0, 0);

    prediction.forEach(function(pred){
        ctxFace.beginPath();
        ctxFace.lineWidth = "4";
        ctxFace.strokeStyle = "blue";
        ctxFace.rect(
            pred.topLeft[0],
            pred.topLeft[1],
            pred.bottomRight[0] - pred.topLeft[0],
            pred.bottomRight[1] - pred.topLeft[1]
        );
        ctxFace.stroke();
    });
};

videoPreview.addEventListener("loadeddata", async function(){
    
    model_face = await blazeface.load();
    console.log("ok");
    setInterval(faceRecognizition,30);
    //copyAudio();
    videoView.play();
    // Hide the videoPreview element
  videoPreview.style.visibility = "hidden";
});

 //================================================================================

// Hide the videoPreview element
//videoPreview.style.visibility = 'hidden';
//------------------------------------------
//--------AudioWave-------------------------
//------------------------------------------
// Get a reference to the canvas and the audio context
var canvasAudio = document.getElementById('audioWave');
var analyser = undefined;
document.getElementById('AudioWaveOn').onclick = function() {
    document.getElementById('AudioWaveOn').disabled = true;
    document.getElementById('AudioWaveOff').disabled = false;
    canvasAudio.hidden = false;
    audioWave();
}
document.getElementById('AudioWaveOff').onclick = function() {
    document.getElementById('AudioWaveOn').disabled = false;
    document.getElementById('AudioWaveOff').disabled = true;
    canvasAudio.hidden = true;
    audioWave();
}


function audioWave(){
    
    var audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    // Create an analyser node
    analyser = audioCtx.createAnalyser();

    // Create a buffer to store the audio data
    var dataArray = new Uint8Array(analyser.frequencyBinCount);

    // Get a reference to the canvas context
    var canvasCtx = canvasAudio.getContext('2d');

    // Function to draw the audio data to the canvas
    function draw() {
        // Get the audio data from the analyser
        analyser.getByteTimeDomainData(dataArray);

        // Clear the canvas
        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
        canvasCtx.fillRect(0, 0, canvasAudio.width, canvasAudio.height);

        // Draw the audio data as a waveform
        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';
        canvasCtx.beginPath();

        var sliceWidth = canvasAudio.width * 1.0 / analyser.frequencyBinCount;
        var x = 0;

        for(var i = 0; i < analyser.frequencyBinCount; i++) {
            var v = dataArray[i] / 128.0;
            var y = v * canvasAudio.height/2;

            if(i === 0) {
                canvasCtx.moveTo(x, y);
            } else {
                canvasCtx.lineTo(x, y);
            }

            x += sliceWidth;
        }

        canvasCtx.lineTo(canvasAudio.width, canvasAudio.height/2);
        canvasCtx.stroke();

        // Call the draw function again on the next animation frame
        requestAnimationFrame(draw);
    }

    // Function to start visualizing the audio
    function startVisualizing(stream) {
        // Create a source from the stream and connect it to the analyser
        var source = audioCtx.createMediaStreamSource(videoPreview.srcObject);
        source.connect(analyser);

        // Start drawing the audio data
        draw();
    }

    // Request access to the microphone
    navigator.mediaDevices.getUserMedia({ audio: true, video: false })
        .then(startVisualizing)
        .catch(function(err) {
            console.log('An error occurred: ' + err);
        });
}


</script>


    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
  </body>
</html>	
